{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T14:12:53.348519Z",
     "start_time": "2019-07-15T14:12:53.342176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T14:12:53.400039Z",
     "start_time": "2019-07-15T14:12:53.351060Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback import *\n",
    "from fastai.train import mixup\n",
    "from fastai.callbacks.mixup import MixUpCallback, MixUpLoss\n",
    "from fastai.basic_train import Learner, LearnerCallback\n",
    "from fastai.vision.image import Image, TfmPixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T14:12:53.642916Z",
     "start_time": "2019-07-15T14:12:53.609834Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "class RicapLoss(nn.Module):\n",
    "    \"Adapt the loss function `crit` to go with ricap data augmentations.\"\n",
    "\n",
    "    def __init__(self, crit, reduction='mean'):\n",
    "        super().__init__()\n",
    "        if hasattr(crit, 'reduction'):\n",
    "            self.crit = crit\n",
    "            self.old_red = crit.reduction\n",
    "            setattr(self.crit, 'reduction', 'none')\n",
    "        else:\n",
    "            self.crit = partial(crit, reduction='none')\n",
    "            self.old_crit = crit\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        if target.ndim == 2:\n",
    "            c_ = target[:, 1:5]\n",
    "            W_ = target[:, 5:]\n",
    "            loss = [W_[:, k] * self.crit(output, c_[:, k].long()) for k in range(4)]\n",
    "            d = torch.mean(torch.stack(loss))\n",
    "        else: d = self.crit(output, target)\n",
    "        if self.reduction == 'mean': return d.mean()\n",
    "        elif self.reduction == 'sum': return d.sum()\n",
    "        return d\n",
    "\n",
    "    def get_old(self):\n",
    "        if hasattr(self, 'old_crit'): return self.old_crit\n",
    "        elif hasattr(self, 'old_red'):\n",
    "            setattr(self.crit, 'reduction', self.old_red)\n",
    "            return self.crit\n",
    "\n",
    "class RicapCallback(LearnerCallback):\n",
    "    \"Callback that creates the ricap input and target.\"\n",
    "    def __init__(self, learn:Learner, beta:float=.3, stack_y:bool=True):\n",
    "        super().__init__(learn)\n",
    "        self.beta,self.stack_y = beta,stack_y\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        if self.stack_y: self.learn.loss_func = RicapLoss(self.learn.loss_func)\n",
    "\n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        \"Applies ricap to `last_input` and `last_target` if `train`.\"\n",
    "        if not train: return\n",
    "        \n",
    "        # get the image size\n",
    "        I_x, I_y = last_input.size()[2:]\n",
    "        \n",
    "        # draw a boundary position (w, h)\n",
    "        w = int(np.round(I_x * np.random.beta(self.beta, self.beta)))\n",
    "        h = int(np.round(I_y * np.random.beta(self.beta, self.beta)))\n",
    "        w_ = [w, I_x - w, w, I_x - w]\n",
    "        h_ = [h, h, I_y - h, I_y - h]\n",
    "       \n",
    "        # select and crop four images\n",
    "        cropped_images = {}\n",
    "        bs = last_input.size(0)\n",
    "        c_ = torch.zeros((bs, 4)).float().to(last_input.device)\n",
    "        W_ = torch.zeros(4).float().to(last_input.device)\n",
    "        for k in range(4):\n",
    "            idx = torch.randperm(bs).to(last_input.device)\n",
    "            x_k = np.random.randint(0, I_x - w_[k] + 1)\n",
    "            y_k = np.random.randint(0, I_y - h_[k] + 1)\n",
    "            cropped_images[k] = last_input[idx][:, :, x_k:x_k + w_[k], y_k:y_k + h_[k]]\n",
    "            c_[:, k] = last_target[idx].float()\n",
    "            W_[k] = w_[k] * h_[k] / (I_x * I_y)\n",
    "        \n",
    "        # patch cropped images\n",
    "        patched_images = torch.cat(\n",
    "            (torch.cat((cropped_images[0], cropped_images[1]), 2),\n",
    "             torch.cat((cropped_images[2], cropped_images[3]), 2)), 3).to(last_input.device)\n",
    "\n",
    "        # modify last target\n",
    "        if self.stack_y:\n",
    "                new_target = torch.cat((last_target[:,None].float(), c_,\n",
    "                                        W_[None].repeat(last_target.size(0), 1)), dim=1)\n",
    "        else:\n",
    "            new_target = c_ * W_\n",
    "        \n",
    "        return {'last_input': patched_images, 'last_target': new_target}\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        if self.stack_y: self.learn.loss_func = self.learn.loss_func.get_old()\n",
    "\n",
    "\n",
    "def ricap(learn:Learner, beta:float=.3, stack_y:bool=True) -> Learner:\n",
    "    \"Add ricap https://arxiv.org/pdf/1811.09030.pdf to `learn`.\"\n",
    "    learn.callback_fns.append(partial(RicapCallback, beta=beta, stack_y=stack_y))\n",
    "    return learn\n",
    "\n",
    "setattr(ricap, 'cb_fn', RicapCallback)\n",
    "Learner.ricap = ricap\n",
    "\n",
    "setattr(mixup, 'cb_fn', MixUpCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T14:12:53.896368Z",
     "start_time": "2019-07-15T14:12:53.868670Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class CutMixCallback(LearnerCallback):\n",
    "    \"Callback that creates the cut mixed-up input and target.\"\n",
    "    def __init__(self, learn:Learner, alpha:float=1., stack_y:bool=True, true_λ:bool=True):\n",
    "        super().__init__(learn)\n",
    "        self.alpha,self.stack_y,self.true_λ = alpha,stack_y,true_λ\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        if self.stack_y: self.learn.loss_func = MixUpLoss(self.learn.loss_func)\n",
    "\n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        \"Applies cutmix to `last_input` and `last_target` if `train`.\"\n",
    "        if not train: return\n",
    "        λ = np.random.beta(self.alpha, self.alpha)\n",
    "        λ = max(λ, 1- λ)\n",
    "        bs = last_target.size(0)\n",
    "        idx = torch.randperm(bs).to(last_input.device)\n",
    "        x1, y1 = last_input[idx], last_target[idx]\n",
    "\n",
    "        #Get new input\n",
    "        last_input_size = last_input.size()\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(last_input_size, λ)\n",
    "        new_input = last_input.clone()\n",
    "        new_input[..., bby1:bby2, bbx1:bbx2] = x1[..., bby1:bby2, bbx1:bbx2]\n",
    "        λ = last_input.new([λ])\n",
    "        λ = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (last_input_size[-1] * last_input_size[-2]))\n",
    "        λ = last_input.new([λ])\n",
    "\n",
    "        # modify last target\n",
    "        if self.stack_y:\n",
    "            new_target = torch.cat([last_target.unsqueeze(1).float(), y1.unsqueeze(1).float(),\n",
    "                                    λ.repeat(last_input_size[0]).unsqueeze(1).float()], 1)\n",
    "        else:\n",
    "            if len(last_target.shape) == 2:\n",
    "                λ = λ.unsqueeze(1).float()\n",
    "            new_target = last_target.float() * λ + y1.float() * (1-λ)\n",
    "        \n",
    "        return {'last_input': new_input, 'last_target': new_target}\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        if self.stack_y: self.learn.loss_func = self.learn.loss_func.get_old()\n",
    "\n",
    "\n",
    "def rand_bbox(last_input_size, λ):\n",
    "    '''lambd is always between .5 and 1'''\n",
    "\n",
    "    W = last_input_size[-1]\n",
    "    H = last_input_size[-2]\n",
    "    cut_rat = np.sqrt(1. - λ) # 0. - .707\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix(learn:Learner, alpha:float=1., stack_x:bool=False, stack_y:bool=True, true_λ:bool=True) -> Learner:\n",
    "    \"Add cutmix https://arxiv.org/pdf/1905.04899.pdf to `learn`.\"\n",
    "    learn.callback_fns.append(partial(CutMixCallback, alpha=alpha, stack_y=stack_y, true_λ=true_λ))\n",
    "    return learn\n",
    "\n",
    "setattr(cutmix, 'cb_fn', CutMixCallback)\n",
    "Learner.cutmix = cutmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T14:12:54.011892Z",
     "start_time": "2019-07-15T14:12:53.999391Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def show_multi_img_tfms(learn, rows=3, cols=3, figsize=(8, 8)):\n",
    "    xb, yb = learn.data.one_batch()\n",
    "    tfms = learn.data.train_ds.tfms\n",
    "    for i in range(len(xb)):\n",
    "        xb[i] = Image(xb[i]).apply_tfms(tfms).data\n",
    "    for cb in learn.callback_fns:\n",
    "        try:\n",
    "            cb_fn = partial(cb.func, **cb.keywords)\n",
    "            [Image(cb_fn(learn).on_batch_begin(\n",
    "                        xb, yb, True)['last_input'][0]).show(ax=ax)\n",
    "                for i, ax in enumerate(\n",
    "                    plt.subplots(rows, cols, figsize=figsize)[1].flatten())]\n",
    "            plt.show()\n",
    "            break\n",
    "        except:\n",
    "            plt.close('all')\n",
    "    return learn\n",
    "\n",
    "\n",
    "Learner.show_multi_img_tfms = show_multi_img_tfms\n",
    "\n",
    "\n",
    "def show_single_img_tfms(learn, rows=3, cols=3, figsize=(8, 8)):\n",
    "    img = learn.data.train_ds.x\n",
    "    tfms = learn.data.train_ds.tfms\n",
    "    rand_int = np.random.randint(len(img))\n",
    "    [img[rand_int].apply_tfms(tfms).show(ax=ax) for i, ax in enumerate(\n",
    "            plt.subplots(rows, cols, figsize=figsize)[1].flatten())]\n",
    "    plt.show()\n",
    "    return learn\n",
    "\n",
    "\n",
    "Learner.show_single_img_tfms = show_single_img_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-15T14:12:53.300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "{\n",
       "    const ip = IPython.notebook\n",
       "    if (ip) {\n",
       "        ip.save_notebook()\n",
       "        console.log('a')\n",
       "        const s = `!python notebook2script.py ${ip.notebook_name}`\n",
       "        if (ip.kernel) { ip.kernel.execute(s) }\n",
       "    }\n",
       "    }"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "{\n",
       "    const ip = IPython.notebook\n",
       "    if (ip) {\n",
       "        ip.save_notebook()\n",
       "        console.log('a')\n",
       "        const s = `!python notebook2script.py ${ip.notebook_name}`\n",
       "        if (ip.kernel) { ip.kernel.execute(s) }\n",
       "    }\n",
       "    }"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "{\n",
       "    const ip = IPython.notebook\n",
       "    if (ip) {\n",
       "        ip.save_notebook()\n",
       "        console.log('a')\n",
       "        const s = `!python notebook2script.py ${ip.notebook_name}`\n",
       "        if (ip.kernel) { ip.kernel.execute(s) }\n",
       "    }\n",
       "    }"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "{\n",
       "    const ip = IPython.notebook\n",
       "    if (ip) {\n",
       "        ip.save_notebook()\n",
       "        console.log('a')\n",
       "        const s = `!python notebook2script.py ${ip.notebook_name}`\n",
       "        if (ip.kernel) { ip.kernel.execute(s) }\n",
       "    }\n",
       "    }"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try: from exp.nb_utils import *\n",
    "except ImportError: from .nb_utils import *\n",
    "nb_auto_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-v1",
   "language": "python",
   "name": "fastai-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:40.732888Z",
     "start_time": "2019-07-20T09:22:40.705201Z"
    },
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blend: a family of data augmentation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:31:50.689560Z",
     "start_time": "2019-07-20T13:31:50.422152Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:31:52.494939Z",
     "start_time": "2019-07-20T13:31:51.123997Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created some code we need to import to be able to use these new data augmentations with the fastai library. Hopefully, one day they will be part of the fastai library and won't need to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:33:24.055552Z",
     "start_time": "2019-07-20T13:33:24.019126Z"
    }
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:31:52.978620Z",
     "start_time": "2019-07-20T13:31:52.947824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/oguiza/.fastai/data/imagenette-160')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size=128\n",
    "bs = 32\n",
    "partial_data = .05\n",
    "path = untar_data(URLs.IMAGENETTE_160); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:31:54.470105Z",
     "start_time": "2019-07-20T13:31:54.002754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (635 items)\n",
       "x: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: CategoryList\n",
       "n03445777,n02102040,n03394916,n03028079,n03000684\n",
       "Path: /home/oguiza/.fastai/data/imagenette-160;\n",
       "\n",
       "Valid: LabelList (34 items)\n",
       "x: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: CategoryList\n",
       "n01440764,n02102040,n03394916,n03425413,n02979186\n",
       "Path: /home/oguiza/.fastai/data/imagenette-160;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (ImageList.from_folder(path)\n",
    "        .use_partial_data(partial_data)\n",
    "        .split_by_folder(valid='val')\n",
    "        .label_from_folder()\n",
    "        .transform(size=size)\n",
    "        .databunch(bs=bs, num_workers=4)\n",
    "        .presize(size, scale=(0.35, 1))\n",
    "        .normalize(imagenet_stats))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:31:57.131586Z",
     "start_time": "2019-07-20T13:31:56.620758Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, models.resnet34())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:33:29.577223Z",
     "start_time": "2019-07-20T13:33:28.453110Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_blend() got an unexpected keyword argument 'blend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f39393f153ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_new_data_augmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgridzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_single_img_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai_extensions/dev/exp/nb_new_data_augmentation.py\u001b[0m in \u001b[0;36mshow_single_img_tfms\u001b[0;34m(learn, rows, cols, figsize)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mrand_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     [img[rand_int].apply_tfms(tfms).show(ax=ax) for i, ax in enumerate(\n\u001b[0;32m--> 288\u001b[0;31m             plt.subplots(rows, cols, figsize=figsize)[1].flatten())]\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai_extensions/dev/exp/nb_new_data_augmentation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mtfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mrand_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     [img[rand_int].apply_tfms(tfms).show(ax=ax) for i, ax in enumerate(\n\u001b[0m\u001b[1;32m    288\u001b[0m             plt.subplots(rows, cols, figsize=figsize)[1].flatten())]\n\u001b[1;32m    289\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-v1/lib/python3.7/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mapply_tfms\u001b[0;34m(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode, remove_out)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresize_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mResizeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCROP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mResizeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_crop_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-v1/lib/python3.7/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;34m\"Randomly execute our tfm on `x`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_run\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_resolve_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTfmList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-v1/lib/python3.7/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, p, is_random, use_on_y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_random\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_on_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;34m\"Calc now if `args` passed; else create a transform called prob `p` if `random`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mRandTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_random\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_on_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_on_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-v1/lib/python3.7/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mcalc\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;34m\"Apply to image `x`, wrapping it if necessary.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m          \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-v1/lib/python3.7/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mpixel\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpixel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPixelFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;34m\"Equivalent to `image.px = func(image.px)`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai_extensions/dev/exp/nb_new_data_augmentation.py\u001b[0m in \u001b[0;36m_gridzero\u001b[0;34m(x, size, alpha, same, proba)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_gridzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_blend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zero'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_gridnoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _blend() got an unexpected keyword argument 'blend'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn.data.train_ds.tfms = [gridzero(size=.05, alpha=.2)]\n",
    "learn.show_single_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GridCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.159962Z",
     "start_time": "2019-07-20T09:22:40.684Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn.data.train_ds.tfms = [gridcut(size=0.05, alpha=1., proba=True)]\n",
    "learn.show_single_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GridMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.160963Z",
     "start_time": "2019-07-20T09:22:40.691Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn.data.train_ds.tfms = [gridmix(size=0.05, alpha=.2, proba=False)]\n",
    "learn.show_single_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RandomZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.161897Z",
     "start_time": "2019-07-20T09:22:40.698Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn.data.train_ds.tfms = [randzero(size=0.05, alpha=.2, proba=True)]\n",
    "learn.show_single_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RandomCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.163347Z",
     "start_time": "2019-07-20T09:22:40.705Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn.data.train_ds.tfms = [randcut(size=0.05, alpha=.2, proba=False)]\n",
    "learn.show_single_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RandomMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.164278Z",
     "start_time": "2019-07-20T09:22:40.712Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn.data.train_ds.tfms = [randmix(size=0.05, alpha=.2, proba=False)]\n",
    "learn.show_single_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.165257Z",
     "start_time": "2019-07-20T09:22:40.719Z"
    }
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn.data.train_ds.tfms = [blend(size=0.05, alpha=.1, blend='noise', grid=True, same=True, proba=True)]\n",
    "learn.show_single_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi-image transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are at least a couple of things multi-image data transforms have in common: \n",
    "\n",
    "- they combine 2 or more images to create a new synthetic image\n",
    "- unlike previous techniques like cutout, the entire image provides informative pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this case I'm creating a databunch without any transforms (other than size) so that it's easier to visualize the real impact of each transformation.\n",
    "\n",
    "This is for demo purposes only. When you use the new data augmentations, you'll be able to decide whether you want to use them jointly with single-image transforms, or just on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:36:43.692426Z",
     "start_time": "2019-07-20T11:36:42.998510Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_folder(path)\n",
    "        .split_by_folder(valid='val')\n",
    "        .label_from_folder()\n",
    "        .transform(size=size) # <-- no transforms \n",
    "        .databunch(bs=bs, num_workers=4)\n",
    "        .presize(size, scale=(0.35, 1))\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I've created a new function (show_multi_img_tfms) that you can use to easily visualize images created by a callback.\n",
    "\n",
    "As you'll see, new data augmentation images are sometimes not realistic to us, but they are helpful to improve performance in vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Mixup (Zhang, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://arxiv.org/abs/1710.09412\n",
    "\n",
    "Mixup blends two images drawn at random from our training data. A weight λ (between .5-1) is assigned to the first sample, and 1-λ to the second one. \n",
    "Despite its simplicity, mixup allows a new state-of-the-art performance in the CIFAR-10, CIFAR- 100, and ImageNet-2012 image classification datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:36:50.718655Z",
     "start_time": "2019-07-20T11:36:48.468086Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, models.resnet34()).mixup()\n",
    "learn.show_multi_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Isn't it weird that this increases performance??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Ricap (Takahashi, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "RICAP (Random Image Cropping and Patching) crops four training images and patches them to construct a new training image; it selects images and determines the cropping sizes randomly, where the size of the final image is identical to that of the original image.\n",
    "\n",
    "RICAP achieves a new state-of-the-art test error of 2.19% on CIFAR-10. We also confirmed that deep CNNs with RICAP achieve better results on classification tasks using CIFAR-100 and ImageNet and an image-caption retrieval task using Microsoft COCO.\n",
    "\n",
    "It's applied in the following way:\n",
    "- a pixel coordinate in the image is randomly selected. That creates 4 areas within an image.\n",
    "- 4 regions from different images are cropped and patched to create a new image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.168855Z",
     "start_time": "2019-07-20T09:22:40.743Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, models.resnet34()).ricap(beta=.1).show_multi_img_tfms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.169787Z",
     "start_time": "2019-07-20T09:22:40.750Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, models.resnet34()).ricap(beta=1.).show_multi_img_tfms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T10:02:36.324133Z",
     "start_time": "2019-07-08T10:02:36.283230Z"
    },
    "hidden": true
   },
   "source": [
    "### Cutmix (Yun, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://arxiv.org/abs/1905.04899\n",
    "\n",
    "Cutmix is similar to Cutout, as a single patch is cut and pasted into a different training image.\n",
    "\n",
    "CutMix consistently outperforms the state-of-the-art augmentation strategies on CIFAR and ImageNet classification tasks, as well as on the ImageNet weakly- supervised localization task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.170912Z",
     "start_time": "2019-07-20T09:22:40.757Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, models.resnet34()).cutmix(alpha=.1).show_multi_img_tfms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.171802Z",
     "start_time": "2019-07-20T09:22:40.762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, models.resnet34()).cutmix(alpha=1.).show_multi_img_tfms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to train using data augmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's super easy! The only thing you need to do is: \n",
    "\n",
    "1. First you will create your ImageDataBunch as you would normally do.\n",
    "You'll need to decide if you want to apply single-image transformations when you create the databunch. If you decide to use it, just add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.173090Z",
     "start_time": "2019-07-20T09:22:40.770Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# single-image transforms\n",
    "tfms = get_transforms()\n",
    "data = (ImageList.from_folder(path)\n",
    "        .split_by_folder(valid='val')\n",
    "        .label_from_folder()\n",
    "        .transform(tfms=tfms, size=size) # <-- single-img transforms\n",
    "        .databunch(bs=bs, num_workers=4)\n",
    "        .presize(size, scale=(0.35, 1))\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2. The you will create the learner as usual, but you will add to it the selected multi-image transform you have selected (mixup, ricap or cutmix). You can only select one of these new data augmentations at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.173974Z",
     "start_time": "2019-07-20T09:22:40.777Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# multi-image transforms\n",
    "learn = Learner(data, models.resnet34()).cutmix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T18:38:24.617897Z",
     "start_time": "2019-07-08T18:38:24.597298Z"
    },
    "hidden": true
   },
   "source": [
    "That's it!!. \n",
    "We can now visualize our images just to check everything's working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.175158Z",
     "start_time": "2019-07-20T09:22:40.784Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.show_multi_img_tfms();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T13:29:16.058821Z",
     "start_time": "2019-07-15T13:29:16.029257Z"
    },
    "hidden": true
   },
   "source": [
    "You can also do both in a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.176126Z",
     "start_time": "2019-07-20T09:22:40.791Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, models.resnet34(), metrics=error_rate).cutmix().show_multi_img_tfms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scheduled tfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Single parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.176999Z",
     "start_time": "2019-07-20T09:22:40.800Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn = Learner(data, models.resnet34(), metrics=accuracy)\n",
    "\n",
    "tfm_fn = partial(gridcut, size=.05, proba=True)\n",
    "sch_param='alpha'\n",
    "sch_val = .25\n",
    "sch_iter = None\n",
    "sch_func = partial(annealing_cos) # annealing_cos, None = annealing_linear, cosine_annealing\n",
    "plot = True\n",
    "test = False\n",
    "sch_tfm_cb = partial(TfmScheduler, tfm_fn=tfm_fn, sch_param=sch_param, sch_val=sch_val, \n",
    "                      sch_iter=sch_iter, sch_func=sch_func, plot=plot, test=test)\n",
    "learn.callback_fns.append(sch_tfm_cb)\n",
    "for cb in learn.callback_fns: print(cb, '\\n')\n",
    "learn.fit_one_cycle(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.177911Z",
     "start_time": "2019-07-20T09:22:40.807Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, models.resnet34(), metrics=accuracy, loss_func = LabelSmoothingCrossEntropy())\n",
    "learn.fit_one_cycle(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.179023Z",
     "start_time": "2019-07-20T09:22:40.812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xb, yb = learn.data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.179970Z",
     "start_time": "2019-07-20T09:22:40.818Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from exp.nb_xresnet_sa import *\n",
    "xresnet34(sa=True)(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Multiple parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.180863Z",
     "start_time": "2019-07-20T09:22:40.826Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "from fastai.callbacks.misc import StopAfterNBatches\n",
    "\n",
    "tfm_fn = partial(gridmix, size=.05, proba=True)\n",
    "sch_param=['alpha', 'size']\n",
    "sch_val = [(.5, 0), (.2, .4)]\n",
    "sch_iter = [.5, .7]\n",
    "sch_func = annealing_cos # annealing_cos, None = annealing_linear\n",
    "plot = True\n",
    "test = False\n",
    "sch_tfm_cb = partial(TfmScheduler, tfm_fn=tfm_fn, sch_param=sch_param, sch_val=sch_val, \n",
    "                      sch_iter=sch_iter, sch_func=sch_func, plot=plot, test=test)\n",
    "\n",
    "\n",
    "learn = Learner(data, models.resnet34(), metrics=accuracy)\n",
    "learn.callback_fns.append(sch_tfm_cb)\n",
    "learn.callbacks.append(StopAfterNBatches(n_batches=2))\n",
    "for cb in learn.callback_fns: print(cb, '\\n')\n",
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.190865Z",
     "start_time": "2019-07-20T09:22:40.890Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "xb, yb = learn.data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.191904Z",
     "start_time": "2019-07-20T09:22:40.895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs = 32\n",
    "data = (ImageList.from_folder(path)\n",
    "        .use_partial_data(0.010)\n",
    "        .split_by_folder(valid='val')\n",
    "        .label_from_folder()\n",
    "        .transform(size=size)\n",
    "        .databunch(bs=bs, num_workers=4)\n",
    "        .presize(size, scale=(0.35, 1))\n",
    "        .normalize(imagenet_stats))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T18:52:31.316194Z",
     "start_time": "2019-07-18T18:52:31.283384Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.192913Z",
     "start_time": "2019-07-20T09:22:40.905Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class TfmScheduler(LearnerCallback):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 learn: Learner,\n",
    "                 tfm_fn: Callable,\n",
    "                 sch_param: str,\n",
    "                 sch_vals: StartOptEnd,\n",
    "                 sch_iters: Optional[StartOptEnd] = None,\n",
    "                 func: Optional[AnnealFunc] = None,\n",
    "                 **kwargs: Any):\n",
    "\n",
    "        super().__init__(learn)\n",
    "        self.batches = math.ceil(len(data.train_ds)/data.train_dl.batch_size)\n",
    "        self.tfm_fn = tfm_fn\n",
    "        self.sch_param = sch_param\n",
    "        self.start_val, self.end_val = (\n",
    "            sch_vals[0], sch_vals[1]) if is_tuple(sch_vals) else (sch_vals, 0)\n",
    "        self.sch_iters = sch_iters\n",
    "        if func is None: self.func = annealing_linear if is_tuple(vals) else annealing_no\n",
    "        else: self.func = func\n",
    "\n",
    "    def on_train_begin(self, n_epochs: int, epoch: int, **kwargs: Any):\n",
    "        total_iters = n_epochs * self.batches\n",
    "        print('n_epochs, epoch, batches, total_iters', n_epochs, epoch, self.batches, total_iters)\n",
    "        if self.sch_iters is None: start_iter, end_iter = (0, total_iters)\n",
    "        else:\n",
    "            start_iter, end_iter = (self.sch_iters[0],self.sch_iters[1]) if is_tuple(\n",
    "                                        self.sch_iters) else (0, self.sch_iters)\n",
    "            if isinstance(start_iter, float): start_iter = int(start_iter * total_iters)\n",
    "            if isinstance(end_iter, float): end_iter = int(end_iter * total_iters)\n",
    "        eff_iters = end_iter - start_iter\n",
    "        self.scheduler = MyScheduler(total_iters, sch_vals, sch_iters=sch_iters, func=func)\n",
    "        self.scheduler.n = 0\n",
    "\n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        param = self.scheduler.step()\n",
    "        if isinstance(self.tfm_fn, functools.partial): \n",
    "            fn = self.tfm_fn.func.func\n",
    "            self.tfm_fn.keywords[self.sch_param] = param\n",
    "            kw = self.tfm_fn.keywords\n",
    "        else: \n",
    "            kw = {self.sch_param: param}\n",
    "            fn = self.tfm_fn.func\n",
    "        new_input = fn(last_input, **kw)\n",
    "        display(Image(new_input[0]))\n",
    "        return {'last_input': new_input, 'last_target': last_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.193769Z",
     "start_time": "2019-07-20T09:22:40.913Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "tfm_fn = partial(gridzero)\n",
    "sch_param='alpha'\n",
    "sch_vals = (0., 1)\n",
    "sch_iters = (.2, .8)\n",
    "func = annealing_cos\n",
    "learn = Learner(data, models.resnet34())\n",
    "learn.callback_fns.append(partial(TfmScheduler, tfm_fn=tfm_fn, sch_param=sch_param, \n",
    "                                  sch_vals=sch_vals, sch_iters=None, func=func))\n",
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.194684Z",
     "start_time": "2019-07-20T09:22:40.918Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fn = tfm_fn.func\n",
    "fn(alpha=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.195535Z",
     "start_time": "2019-07-20T09:22:40.924Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if isinstance(tfm_fn, functools.partial): fn = tfm_fn.func.func\n",
    "else: fn = tfm_fn.func\n",
    "inspect.getfullargspec(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.196410Z",
     "start_time": "2019-07-20T09:22:40.929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.197252Z",
     "start_time": "2019-07-20T09:22:40.935Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inspect.getfullargspec(blender.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.198158Z",
     "start_time": "2019-07-20T09:22:40.940Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xb, yb = learn.data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.199008Z",
     "start_time": "2019-07-20T09:22:40.945Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "out = _blender(xb[0], size=.05, alpha=.2, blend='mix', grid=False, same=True)\n",
    "Image(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.200063Z",
     "start_time": "2019-07-20T09:22:40.951Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "lambd_ = []\n",
    "for i in range(1000):\n",
    "    lambd = np.random.beta(alpha, alpha)\n",
    "    lambd = max(lambd, 1- lambd)\n",
    "    lambd_.append(1-lambd)\n",
    "plt.hist(lambd_, 100)\n",
    "plt.show()\n",
    "print(np.mean(lambd_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.200916Z",
     "start_time": "2019-07-20T09:22:40.957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "lambd_ = []\n",
    "for i in range(1000):\n",
    "    lambd = np.random.beta(alpha, alpha)\n",
    "    #lambd = max(lambd, 1- lambd)\n",
    "    lambd_.append(lambd)\n",
    "plt.hist(lambd_, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.201756Z",
     "start_time": "2019-07-20T09:22:40.963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alpha = .2\n",
    "patch_len = 400\n",
    "\n",
    "lambd = np.random.beta(alpha, alpha)\n",
    "lambd = max(lambd, 1- lambd)\n",
    "patch_ids = np.random.choice(np.arange(patch_len), int(patch_len * (1 - lambd)), replace=False)\n",
    "len(patch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.202599Z",
     "start_time": "2019-07-20T09:22:40.968Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "start = 0\n",
    "width = .5\n",
    "x = sp.stats.uniform.rvs(size=n, loc = start, scale=width)\n",
    "plt.hist(x, 100)\n",
    "plt.show()\n",
    "print(x.mean(), x.std(), sp.stats.skew(x), sp.stats.kurtosis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.203528Z",
     "start_time": "2019-07-20T09:22:40.974Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = sp.stats.norm.rvs(size=10000,loc=0,scale=1)\n",
    "plt.hist(x, 100)\n",
    "plt.show()\n",
    "print(x.mean(), x.std(), sp.stats.skew(x), sp.stats.kurtosis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.204453Z",
     "start_time": "2019-07-20T09:22:40.980Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = sp.stats.expon.rvs(scale=1,loc=0,size=1000)\n",
    "x = x / x.max()\n",
    "plt.hist(x, 100)\n",
    "plt.show()\n",
    "print(x.mean(), x.std(), sp.stats.skew(x), sp.stats.kurtosis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.205354Z",
     "start_time": "2019-07-20T09:22:40.985Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_expon = expon.rvs(scale=1,loc=0,size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Uniform (alpha = 1., fixed_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.206301Z",
     "start_time": "2019-07-20T09:22:40.993Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "alpha = 1\n",
    "x = np.random.beta(alpha, alpha, size=(10000, 1)) * .5\n",
    "#x = np.concatenate((x, 1 - x), axis=1).min(1)\n",
    "plt.hist(x, 100)\n",
    "plt.show()\n",
    "print(x.mean(), x.std(), sp.stats.skew(x), sp.stats.kurtosis(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Gaussian (alpha="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.207204Z",
     "start_time": "2019-07-20T09:22:41.213Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "alpha = 5\n",
    "x = np.random.beta(alpha, alpha, size=(10000, 1))\n",
    "plt.hist(x, 100)\n",
    "plt.show()\n",
    "print(x.mean(), x.std(), sp.stats.skew(x), sp.stats.kurtosis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.208224Z",
     "start_time": "2019-07-20T09:22:41.221Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "x = np.random.normal(size=10000)\n",
    "x = (x - x.min()) / (x.max() - x.min()) * .5\n",
    "plt.hist(x, 100)\n",
    "plt.show()\n",
    "print(x.mean(), x.std(), sp.stats.skew(x), sp.stats.kurtosis(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.209135Z",
     "start_time": "2019-07-20T09:22:41.229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "alpha = .3\n",
    "x = np.random.beta(1, alpha, size=(10000, 1))\n",
    "x = np.concatenate((x, 1 - x), axis=1).min(1)\n",
    "plt.hist(x, 100)\n",
    "plt.show()\n",
    "print(x.mean(), x.std(), sp.stats.skew(x), sp.stats.kurtosis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T09:22:43.209980Z",
     "start_time": "2019-07-20T09:22:41.240Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size = .05\n",
    "alpha = .25\n",
    "proba_type = 'beta' # '', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:10:45.561436Z",
     "start_time": "2019-07-20T11:10:45.516341Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RicapCallback(LearnerCallback):\n",
    "    \"Callback that creates the ricap input and target.\"\n",
    "    def __init__(self, learn:Learner, beta:float=.3, stack_y:bool=True, \n",
    "                 rand:bool=True, shuffle:bool=True):\n",
    "        super().__init__(learn)\n",
    "        self.beta,self.stack_y,self.rand,self.shuffle = beta,stack_y,rand,shuffle\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        if self.stack_y and self.shuffle: self.learn.loss_func = RicapLoss(self.learn.loss_func)\n",
    "\n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        \"Applies ricap to `last_input` and `last_target` if `train`.\"\n",
    "        if not train: return\n",
    "        # get the image size\n",
    "        I_x, I_y = last_input.size()[2:]\n",
    "        \n",
    "        # draw a boundary position (w, h)\n",
    "        w = int(np.round(I_x * np.random.beta(self.beta, self.beta)))\n",
    "        h = int(np.round(I_y * np.random.beta(self.beta, self.beta)))\n",
    "        if self.rand:\n",
    "            w_ = [w, I_x - w, w, I_x - w]\n",
    "            h_ = [h, h, I_y - h, I_y - h]\n",
    "        else:\n",
    "            h_from = [0, 0, h, h]\n",
    "            h_to = [h, h, I_y, I_y]\n",
    "            w_from = [0, w, 0, w]\n",
    "            w_to = [w, I_x, w, I_x]\n",
    "        \n",
    "        # select and crop four images\n",
    "        cropped_images = {}\n",
    "        bs = last_input.size(0)\n",
    "        c_ = torch.zeros((bs, 4)).float().to(last_input.device)\n",
    "        W_ = torch.zeros(4).float().to(last_input.device)\n",
    "        for k in range(4):\n",
    "            if self.shuffle: idx = torch.randperm(bs).to(last_input.device)\n",
    "            else: idx = torch.linspace(0, bs - 1, steps=bs).to(dtype=torch.int64, device=last_input.device)\n",
    "            if self.rand:\n",
    "                x_k = np.random.randint(0, I_x - w_[k] + 1)\n",
    "                y_k = np.random.randint(0, I_y - h_[k] + 1)\n",
    "                cropped_images[k] = last_input[idx][:, :, x_k:x_k + w_[k], y_k:y_k + h_[k]]\n",
    "                c_[:, k] = last_target[idx].float() # cropping labels\n",
    "                W_[k] = w_[k] * h_[k] / (I_x * I_y) # cropping weights\n",
    "            else:\n",
    "                cropped_images[k] = last_input[idx][:, :, h_from[k]:h_to[k], w_from[k]:w_to[k]]\n",
    "                c_[:, k] = last_target[idx].float()\n",
    "                W_[k] = (h_to[k] - h_from[k]) * (w_to[k] - w_from[k]) / (I_x * I_y)\n",
    "            print(W_[k])\n",
    "        # patch cropped images\n",
    "        if self.rand:\n",
    "            patched_images = torch.cat(\n",
    "                (torch.cat((cropped_images[0], cropped_images[1]), 2),\n",
    "                 torch.cat((cropped_images[2], cropped_images[3]), 2)), 3)  #.cuda()\n",
    "        else:\n",
    "            patched_images = torch.cat(\n",
    "                (torch.cat((cropped_images[0], cropped_images[2]), 2),\n",
    "                 torch.cat((cropped_images[1], cropped_images[3]), 2)), 3) \n",
    "            \n",
    "\n",
    "        # modify last target\n",
    "        if self.shuffle:\n",
    "            new_target = torch.cat((last_target[:,None].float(), c_,\n",
    "                                    W_[None].repeat(last_target.size(0), 1)), \n",
    "                                   dim=1)\n",
    "        else: new_target = last_target\n",
    "        #print(new_target)\n",
    "        #return\n",
    "        #print(new_target.shape)\n",
    "        #print(last_target[:,None].float().shape)\n",
    "        #print(c_.shape)\n",
    "        #print(W_[None].repeat(last_target.size(0), 1).shape)\n",
    "        #print()\n",
    "        \n",
    "        return {'last_input': patched_images, 'last_target': new_target}\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        if self.stack_y and self.shuffle: self.learn.loss_func = self.learn.loss_func.get_old()\n",
    "\n",
    "\n",
    "def ricap(learn:Learner, beta:float=.3, stack_y:bool=True, rand:bool=True) -> Learner:\n",
    "    \"Add ricap https://arxiv.org/pdf/1811.09030.pdf to `learn`.\"\n",
    "    learn.callback_fns.append(partial(RicapCallback, beta=beta, \n",
    "                                      stack_y=stack_y, rand=rand))\n",
    "    return learn\n",
    "\n",
    "\n",
    "setattr(ricap, 'cb_fn', RicapCallback)\n",
    "Learner.ricap = ricap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:23:15.287231Z",
     "start_time": "2019-07-20T11:23:15.249291Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def _blend(x, size:tuple=(.5, .2), alpha:float=.3, fixed_proba:float=0., \n",
    "           blend_type:str='cut', grid:bool=True,  same_size:bool=True):\n",
    "    ''' Modifies one or multiple subregions of an image\n",
    "        Parameters:\n",
    "        size: \n",
    "            int tuple(height pixels, wide pixels), float tuple (height % img, wide % img)\n",
    "            int (pixels) or float (percent_tuple)\n",
    "        alpha: proba that each patch is modified from np.random.beta(alpha, alpha)\n",
    "        fixed_proba: proba that each individual patch is modified. If >0 overrides alpha.\n",
    "        blend_type: 'zero', 'noise', 'mix', 'cut' or 'rand'(any of the previous)\n",
    "        grid: True patches will be part of a grid, so they won't overlap\n",
    "        same_size: True all grid cells will have approx the same size, otherwise random'''\n",
    "\n",
    "    if size == 0 or (alpha == 0 and fixed_proba == 0): return x\n",
    "    if not isinstance(size, tuple): size = (size, size)\n",
    "    if isinstance(size[0], float): h = int(size[1] * x_size[-2])\n",
    "    else: h = size[0]\n",
    "    if isinstance(size[1], float): w = int(size[0] * x_size[-1])\n",
    "    else: w = size[1]\n",
    "    if w == 0 or h == 0: return x\n",
    "    x_size = x.shape\n",
    "    new_x = x.clone()\n",
    "    \n",
    "    # patches that will be modified\n",
    "    n_patches = (x_size[0] // h, x_size[1] // w)\n",
    "    patch_len = n_patches[0] * n_patches[1]\n",
    "    if fixed_proba != 0:\n",
    "        patch_ids = np.arange(patch_len)[np.random.rand(patch_len) <= fixed_proba]\n",
    "    else:\n",
    "        lambd = np.random.beta(alpha, alpha)\n",
    "        lambd = max(lambd, 1- lambd)\n",
    "        patch_ids = np.random.choice(np.arange(patch_len), \n",
    "                                     int(patch_len * (1 - lambd)), \n",
    "                                     replace=False)\n",
    "    \n",
    "    if blend.lower() == 'rand': _blend = np.random.choice(['zero', 'noise', 'mix', 'cut'])\n",
    "    else: _blend = blend.lower()\n",
    "\n",
    "    if grid: patches = get_x1_coords(x_size, n_patches, same_size=same_size)\n",
    "    for i in patch_ids:\n",
    "        #x1 coordinates\n",
    "        if grid: bby1, bby2, bbx1, bbx2 = patches[i]\n",
    "        else: bby1, bby2, bbx1, bbx2 = get_x1_rand_coords(x_size, n_patches, w, h)\n",
    "        # Blend\n",
    "        if _blend == 'zero': new_x[..., bby1:bby2, bbx1:bbx2] = 0\n",
    "        if _blend == 'noise': \n",
    "            noise = x.new(np.random.rand(bby2 - bby1, bbx2 - bbx1))\n",
    "            new_x[..., bby1:bby2, bbx1:bbx2] = noise\n",
    "        else: \n",
    "            #x2 coordinates\n",
    "            ccy1, ccy2, ccx1, ccx2 = get_x2_coords(x_size, bby1, bby2, bbx1, bbx2)\n",
    "            x2 = x[..., ccy1:ccy2, ccx1:ccx2]\n",
    "            if _blend == 'mix':\n",
    "                x1 = x[..., bby1:bby2, bbx1:bbx2]\n",
    "                new_x[..., bby1:bby2, bbx1:bbx2] = x1 * .5 + x2 * .5\n",
    "            if _blend == 'cut':\n",
    "                new_x[..., bby1:bby2, bbx1:bbx2] = x2\n",
    "    return new_x\n",
    "\n",
    "blender = TfmPixel(_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T12:39:26.623330Z",
     "start_time": "2019-07-20T12:39:26.591403Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "class BlendLoss(nn.Module):\n",
    "    \"Adapt the loss function `crit` to go with blend data augmentations.\"\n",
    "\n",
    "    def __init__(self, crit, reduction='mean'):\n",
    "        super().__init__()\n",
    "        if hasattr(crit, 'reduction'):\n",
    "            self.crit = crit\n",
    "            self.old_red = crit.reduction\n",
    "            setattr(self.crit, 'reduction', 'none')\n",
    "        else:\n",
    "            self.crit = partial(crit, reduction='none')\n",
    "            self.old_crit = crit\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        #print('loss output target input:', output.shape, target.shape)\n",
    "        if target.ndim == 2:# and target.shape[-1] >1:\n",
    "            n_mod_patches = (target.shape[-1] - 1) // 2\n",
    "            c_ = target[:, 1:n_mod_patches + 1]\n",
    "            W_ = target[:, n_mod_patches + 1:]\n",
    "            loss = [W_[:, k] * self.crit(output, c_[:, k].long()) for k in range(n_mod_patches)]\n",
    "            d = torch.mean(torch.stack(loss))\n",
    "        else: d = self.crit(output, target)\n",
    "        if self.reduction == 'mean': return d.mean()\n",
    "        elif self.reduction == 'sum': return d.sum()\n",
    "        return d\n",
    "\n",
    "    def get_old(self):\n",
    "        if hasattr(self, 'old_crit'): return self.old_crit\n",
    "        elif hasattr(self, 'old_red'):\n",
    "            setattr(self.crit, 'reduction', self.old_red)\n",
    "            return self.crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:31:14.186438Z",
     "start_time": "2019-07-20T13:31:14.115371Z"
    }
   },
   "outputs": [],
   "source": [
    "class BlendCallback(LearnerCallback):\n",
    "    \"Callback that creates the blend input and target.\"\n",
    "    def __init__(self, learn:Learner, \n",
    "                 size:tuple=(.1, .1), alpha:float=1., fixed_proba:float=0., \n",
    "                 blend_type:str='cut', same_size:bool=True,\n",
    "                 same_crop:bool=True, same_image:bool=False):\n",
    "        ''' Modifies one or multiple subregions of an image\n",
    "        Parameters:\n",
    "        size: \n",
    "            int tuple(height pixels, wide pixels), float tuple (height % img, wide % img)\n",
    "            int (pixels) or float (percent_tuple)\n",
    "            None full image\n",
    "        alpha: proba that each patch is modified from np.random.beta(alpha, alpha)\n",
    "        fixed_proba: proba that each individual patch is modified. If >0 overrides alpha.\n",
    "        blend_type: 'zero', 'noise', 'mix', 'cut' or 'rand'(any of the previous)\n",
    "        same_size: True - all patches will have approx the same size, otherwise random\n",
    "        same_crop: cropping subregion will be the same as input subregion, otherwise different\n",
    "        same_image: False - cropping image will be different from input image, otherwise same\n",
    "        '''\n",
    "        assert blend_type in ['zero', 'noise', 'mix', 'cut', 'random'], \\\n",
    "        print(\"make sure you select one of these blend_types: 'zero', 'noise', 'mix', 'cut', 'random'\")\n",
    "        super().__init__(learn)\n",
    "        self.size,self.alpha,self.fixed_proba,self.blend_type = size,alpha,fixed_proba,blend_type\n",
    "        self.same_size,self.same_crop,self.same_image = same_size,same_crop,same_image\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        if not self.same_image: self.learn.loss_func = BlendLoss(self.learn.loss_func)\n",
    "\n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        \"Applies blend to `last_input` and `last_target` if `train`.\"\n",
    "        if not train: return {'last_input': last_input, 'last_target': last_target}\n",
    "        if self.alpha == 0 and self.fixed_proba == 0: \n",
    "            return {'last_input': last_input, 'last_target': last_target}\n",
    "\n",
    "        x_size = last_input.size()\n",
    "        bs = x_size[0] # batch size\n",
    "        i_h, i_w = x_size[2:] # image height, width\n",
    "        if not isinstance(self.size, tuple): self.size = (self.size, self.size)\n",
    "        p_h, p_w = self.size # patch percent height, width\n",
    "        if p_h == 1 or isinstance(p_h, float): h = int(p_h * i_h) # patch height in pixels\n",
    "        else: h = p_h\n",
    "        if p_w == 1 or isinstance(p_w, float): w = int(p_w * i_w) # patch width in pixels\n",
    "        else: w = p_w\n",
    "        if w == 0 or h == 0: return {'last_input': last_input, 'last_target': last_target}\n",
    "        patched_images = last_input.clone()\n",
    "\n",
    "        # patches that will be modified\n",
    "        n_patches = (i_h // h, i_w // w)\n",
    "        patch_len = n_patches[0] * n_patches[1]\n",
    "        patches = get_x1_coords(x_size, n_patches, same_size=self.same_size)\n",
    "        if self.fixed_proba != 0:\n",
    "            lambd = self.fixed_proba\n",
    "        else:\n",
    "            lambd = np.random.beta(self.alpha, self.alpha)\n",
    "            lambd = max(lambd, 1- lambd)\n",
    "        if patch_len == 1: patch_ids = [0]\n",
    "        elif self.fixed_proba != 0:\n",
    "            patch_ids = np.arange(patch_len)[np.random.rand(patch_len) <= lambd]\n",
    "        else:\n",
    "            patch_ids = np.random.choice(np.arange(patch_len), int(patch_len * (1 - lambd)), replace=False)\n",
    "        n_mod_patches = len(patch_ids)\n",
    "        if n_mod_patches == 0: return {'last_input': last_input, 'last_target': last_target}\n",
    "        mod_patches = [patches[i] for i in patch_ids]\n",
    "        c_ = torch.zeros((bs, n_mod_patches)).float().to(last_input.device) # patch labels\n",
    "        W_ = torch.zeros(n_mod_patches).float().to(last_input.device) # new weights\n",
    "        idx = torch.linspace(0, bs - 1, steps=bs).to(dtype=torch.int64, device=last_input.device)\n",
    "        if self.blend_type.lower() == 'random': _blend = np.random.choice(['zero', 'noise', 'mix', 'cut'])\n",
    "        else: _blend = self.blend_type.lower()\n",
    "        for j, patch in enumerate(mod_patches):\n",
    "            #x1 coordinates\n",
    "            bby1, bby2, bbx1, bbx2 = patch\n",
    "            # Blend\n",
    "            if _blend == 'zero': patched_images[..., bby1:bby2, bbx1:bbx2] = 0\n",
    "            if _blend == 'noise': \n",
    "                noise = last_input.new(np.random.rand(bby2 - bby1, bbx2 - bbx1))\n",
    "                patched_images[..., bby1:bby2, bbx1:bbx2] = noise\n",
    "            else: \n",
    "                if not self.same_image: idx = torch.randperm(bs).to(last_input.device)\n",
    "                #x2 coordinates\n",
    "                if self.same_crop: \n",
    "                    x2 = last_input[idx][..., bby1:bby2, bbx1:bbx2]\n",
    "                else:\n",
    "                    ccy1, ccy2, ccx1, ccx2 = get_x2_coords(x_size, bby1, bby2, bbx1, bbx2)\n",
    "                    x2 = last_input[idx][..., ccy1:ccy2, ccx1:ccx2]\n",
    "                if _blend == 'mix':\n",
    "                    x1 = last_input[..., bby1:bby2, bbx1:bbx2]\n",
    "                    if self.size == (1, 1): \n",
    "                        patched_images[..., bby1:bby2, bbx1:bbx2] = x1 * lambd + x2 * (1 - lambd)\n",
    "                    else: patched_images[..., bby1:bby2, bbx1:bbx2] = x1 * .5 + x2 * .5\n",
    "                if _blend == 'cut':\n",
    "                    patched_images[..., bby1:bby2, bbx1:bbx2] = x2\n",
    "            W_[j] = (bby2 - bby1) * (bbx2 - bbx1) / (i_w * i_h)\n",
    "            c_[:, j] = last_target[idx].float()\n",
    "        # modify last target\n",
    "        if not self.same_image and n_mod_patches > 0:\n",
    "            new_target = torch.cat((last_target[:,None].float(), c_, W_[None].repeat(bs, 1)), dim=1)\n",
    "        else: new_target = last_target\n",
    "        return {'last_input': patched_images, 'last_target': new_target}\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        if not self.same_image: self.learn.loss_func = self.learn.loss_func.get_old()\n",
    "\n",
    "\n",
    "def blend_mgr(learn:Learner, size:tuple=(.1, .1), alpha:float=1., \n",
    "          fixed_proba:float=0., blend_type:str='cut', \n",
    "          same_size:bool=True, same_crop:bool=True, same_image:bool=False) -> Learner:\n",
    "    learn.callback_fns.append(partial(BlendCallback, size=size, alpha=alpha, \n",
    "                                      fixed_proba=fixed_proba, blend_type=blend_type, \n",
    "                                      same_size=same_size, same_crop=same_crop, same_image=same_image))\n",
    "    return learn\n",
    "\n",
    "setattr(blend_mgr, 'cb_fn', BlendCallback)\n",
    "Learner.blend_mgr = blend_mgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:31:19.342317Z",
     "start_time": "2019-07-20T13:31:18.394675Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#RICAP\n",
    "size = .5\n",
    "alpha = 1\n",
    "fixed_proba = 1     # this will override alpha\n",
    "blend_type = 'cut' # 'zero', 'noise', 'mix', 'cut', 'random'\n",
    "same_size = False\n",
    "same_crop = False    # only with 'mix' and 'cut'\n",
    "same_image = False    # only with 'mix' and 'cut'\n",
    "\n",
    "learn = Learner(data, models.resnet34()).blend(\n",
    "    size=size,\n",
    "    alpha=alpha,\n",
    "    fixed_proba=fixed_proba,\n",
    "    blend_type=blend_type,\n",
    "    same_size=same_size,\n",
    "    same_crop=same_crop,\n",
    "    same_image=same_image).show_multi_img_tfms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:17:00.153889Z",
     "start_time": "2019-07-20T13:15:53.712185Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from exp.nb_new_data_augmentation import *\n",
    "learn = Learner(data, models.resnet34(), metrics=accuracy)\n",
    "\n",
    "size = .1\n",
    "alpha = .2\n",
    "fixed_proba = 0.\n",
    "blend_type = 'noise'\n",
    "same_size = True\n",
    "same_crop = True\n",
    "same_image = False\n",
    "tfm_fn = partial(blend, size=size, alpha=alpha, fixed_proba=fixed_proba, blend_type=blend_type,\n",
    "                 same_size=same_size, same_crop=same_crop, same_image=same_image)\n",
    "\n",
    "sch_param='alpha'\n",
    "sch_val = (.25, .5)\n",
    "sch_iter = (0, .3)\n",
    "sch_func = annealing_cos # annealing_cos, None = annealing_linear, cosine_annealing\n",
    "plot = True\n",
    "test = False  # if True this will stop training in the first mini-batch\n",
    "sch_tfm_cb = partial(TfmScheduler, tfm_fn=tfm_fn, sch_param=sch_param, sch_val=sch_val, \n",
    "                      sch_iter=sch_iter, sch_func=sch_func, plot=plot, test=test)\n",
    "learn.callback_fns.append(sch_tfm_cb)\n",
    "for cb in learn.callback_fns: print(cb, '\\n')\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T13:04:45.267823Z",
     "start_time": "2019-07-20T13:04:45.241996Z"
    }
   },
   "outputs": [],
   "source": [
    "tfm_fn.func.cb_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T10:07:09.887311Z",
     "start_time": "2019-07-20T10:07:09.354017Z"
    }
   },
   "outputs": [],
   "source": [
    "xb,yb = learn.data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T10:09:13.022417Z",
     "start_time": "2019-07-20T10:09:12.950069Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "partial(BlendCallback, **{\n",
    "        'size': 0.1,\n",
    "        'alpha': 0.0,\n",
    "        'fixed_proba': 0.0,\n",
    "        'blend_type': 'noise',\n",
    "        'same_size': True,\n",
    "        'same_crop': True,\n",
    "        'same_image': False\n",
    "    }).on_batch_begin(xb, yb, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T10:10:11.443349Z",
     "start_time": "2019-07-20T10:10:11.380021Z"
    }
   },
   "outputs": [],
   "source": [
    "tfm_fn = partial(BlendCallback, size=size, alpha=alpha, fixed_proba=fixed_proba, blend_type=blend_type,\n",
    "                 same_size=same_size, same_crop=same_crop, same_image=same_image)\n",
    "\n",
    "tfm_fn.keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T10:13:32.318365Z",
     "start_time": "2019-07-20T10:13:32.249173Z"
    }
   },
   "outputs": [],
   "source": [
    "new_input, new_target = BlendCallback.on_batch_begin(last_input=xb,last_target=yb,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T10:19:46.784942Z",
     "start_time": "2019-07-20T10:19:46.711078Z"
    }
   },
   "outputs": [],
   "source": [
    "blender(learn, size=(.1, .1), alpha=1., fixed_proba=0., \n",
    "                 blend_type='cut', same_size=True,\n",
    "                 same_crop=True, same_image=False).on_batch_begin(last_input=xb,last_target=yb,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T10:21:20.299398Z",
     "start_time": "2019-07-20T10:21:20.241040Z"
    }
   },
   "outputs": [],
   "source": [
    "tfm_fn = partial(BlendCallback, size=size, alpha=alpha, fixed_proba=fixed_proba, blend_type=blend_type,\n",
    "                 same_size=same_size, same_crop=same_crop, same_image=same_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T10:23:15.186381Z",
     "start_time": "2019-07-20T10:23:15.124846Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-v1",
   "language": "python",
   "name": "fastai-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
